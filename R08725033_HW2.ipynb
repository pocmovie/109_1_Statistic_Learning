{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 統計學習與深度學習\n",
    "### Homework 2\n",
    "R08725033 資管碩二 陳柏勳"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第一題 [Data Preprocessing]\n",
    "本題依序進行以下操作（處理）：\n",
    "* 使用Pandas讀入UCI dataset的train和test資料集\n",
    "* 處理NAN，還有文件中提及的\"?\"等缺漏值\n",
    "* 轉換50k to 0 and 1\n",
    "* 將test和train暫時合併，以進行一致的標準化。針對num_col透過sklearn的StandardScaler進行標準化；對cat_col使用pandas的get_dummies進行1-of-k的encoding，並丟棄整列中出現少於10個觀察值的列。\n",
    "* 和adult50kp['columnname']進行對齊，並將label列指定成y值\n",
    "* 藉由train.index的長度還原回train/ test\n",
    "* 最後轉換成numpy的資料型態"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/load-machine-learning-data-python/\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "names = ['age', 'workclass', 'fnlwgt', 'education', 'educational-num', 'marital-status', 'occupation', 'relationship'\n",
    "         , 'race', 'gender', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'label']\n",
    "train = pd.read_csv('adult.data', names=names, sep=', ', engine='python')\n",
    "test = pd.read_csv('adult.test', names=names, sep=', ', engine='python')\n",
    "\n",
    "# pd.isna(train).any()\n",
    "train.dropna()\n",
    "# pd.isna(test).any()\n",
    "test.dropna()\n",
    "\n",
    "# Convert Unknown to \"?\", so remove it.\n",
    "# https://stackoverflow.com/questions/36620175/futurewarning-elementwise-comparison-failed-returning-scalar-instead\n",
    "train = train[(train.astype(str) != '?').all(axis=1)] # All feature isn't ? in the row, reduce columns\n",
    "test = test[(test.astype(str) != '?').all(axis=1)]\n",
    "\n",
    "# len(train): 32561 to 30162\n",
    "\n",
    "# Transfer label to 1 and 0\n",
    "# https://blog.csdn.net/xueruixuan/article/details/80237481\n",
    "train.loc[:,'label'] = train.loc[:,'label'].map({'>50K':1, '<=50K':0})\n",
    "test.loc[:,'label'] = test.loc[:,'label'].map({'>50K.':1, '<=50K.':0})\n",
    "\n",
    "num_col = ['age', 'fnlwgt', 'educational-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "cat_col = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country']\n",
    "\n",
    "# Use all data to normalize, make sure the meaning is same\n",
    "all_data = pd.concat([train, test], axis=0)\n",
    "\n",
    "# Normalize num data\n",
    "xscaler = preprocessing.StandardScaler().fit(all_data.loc[:,num_col])\n",
    "all_data.loc[:,num_col] = xscaler.transform(all_data.loc[:,num_col])\n",
    "\n",
    "# https://medium.com/@PatHuang/%E5%88%9D%E5%AD%B8python%E6%89%8B%E8%A8%98-3-%E8%B3%87%E6%96%99%E5%89%8D%E8%99%95%E7%90%86-label-encoding-one-hot-encoding-85c983d63f87\n",
    "all_data = pd.get_dummies(all_data, columns = cat_col)\n",
    "\n",
    "# https://www.delftstack.com/zh-tw/howto/python-pandas/how-to-get-the-sum-of-pandas-column/\n",
    "for c in all_data.columns:\n",
    "    if all_data[c].sum()>=1 and all_data[c].sum()<10:\n",
    "        all_data = all_data.drop(c,axis=1)\n",
    "        \n",
    "'''\n",
    "Align with the order in adult_m50k.pickle\n",
    "'''\n",
    "dsfile = 'adult_m50k.pickle'\n",
    "with open(dsfile, 'rb') as fh1:\n",
    "    adult50kp = pickle.load(fh1)\n",
    "    \n",
    "# Align it\n",
    "all_data_sort = all_data.loc[:,adult50kp['columnname']]\n",
    "\n",
    "# Split to x and y\n",
    "all_y = all_data.loc[:,'label']\n",
    "\n",
    "# Split to train and test\n",
    "x_train = all_data_sort.iloc[:len(train.index),:]\n",
    "x_test = all_data_sort.iloc[len(train.index):,:]\n",
    "y_train = all_y[:len(train.index)]\n",
    "y_test = all_y[len(train.index):]\n",
    "\n",
    "# To numpy\n",
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train match!\n",
      "x_test match!\n",
      "y_train match!\n",
      "y_test match!\n"
     ]
    }
   ],
   "source": [
    "elems = ['x_train', 'x_test', 'y_train', 'y_test']\n",
    "\n",
    "for aelem in elems:\n",
    "    cnomatch = np.sum(adult50kp[aelem] != adult50kp[aelem])\n",
    "    if cnomatch == 0:\n",
    "        print(aelem, \"match!\")\n",
    "    else:\n",
    "        print(aelem, \"%d elements no match!\" % cnomatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前處理完後的結果，和題目提供的\"adult_m50k.pickle\"吻合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第二題 [ROC and AUC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.848340\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# load dataset\n",
    "dsfile = 'adult_m50k.pickle'\n",
    "with open(dsfile, 'rb') as fh1:\n",
    "    adult50kp = pickle.load(fh1)\n",
    "    \n",
    "#train prediction model    \n",
    "c = 0.3\n",
    "lr2 = LogisticRegression(solver = 'lbfgs', C= c, max_iter = 1000)\n",
    "lr2.fit(adult50kp['x_train'], adult50kp['y_train'])\n",
    "#make prediction\n",
    "ypred = lr2.predict(adult50kp['x_test'])\n",
    "ypredprob = lr2.predict_proba(adult50kp['x_test'])\n",
    "#compute accuracy\n",
    "ncorrect = np.sum(adult50kp['y_test'] == ypred)\n",
    "accuracy_sk = ncorrect / adult50kp['y_test'].shape[0]\n",
    "print(\"Accuracy = %f\" % accuracy_sk)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Q2.1 (17.5%): 基於`adult50kp['y_test']`與`ypredprob`繪製ROC Curve。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本題依序進行以下操作（處理）：\n",
    "* 以0.01為間距，計算threshold自p=0~1（每次提高0.01）的TPR和FPR\n",
    "* 再和亂猜的45度角線進行比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x23d86371088>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# p = 0, TP = TP + FN, FP = FP + TN (All positive)\n",
    "TPR = [1]\n",
    "FPR = [1]\n",
    "\n",
    "for p in range(0, 100):\n",
    "    \n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    TN = 0\n",
    "    \n",
    "    for i in range(len(ypredprob)):\n",
    "        if ypredprob[i][0] > p/100 and adult50kp['y_test'][i]==0:\n",
    "            TP += 1\n",
    "        elif ypredprob[i][0] > p/100 and adult50kp['y_test'][i]==1:\n",
    "            FP += 1\n",
    "        elif ypredprob[i][0] < p/100 and adult50kp['y_test'][i]==0:\n",
    "            FN += 1\n",
    "        else:\n",
    "            TN += 1\n",
    "    \n",
    "    TPR.append(TP/(TP+FN))\n",
    "    FPR.append(FP/(FP+TN))\n",
    "\n",
    "# p = 1, TP = 0, FP = 0 (All negative)\n",
    "TPR.append(0)\n",
    "FPR.append(0)\n",
    "\n",
    "# https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(FPR, TPR, label='Logistic')\n",
    "plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由ROC Curve可知，本題給定的模型\"Reasonable separation between the classes, mostly convex.\" Ex. 在TPR = 0.8時，FPR處在約莫0.18的不錯表現。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Q2.2 (17.5%): 計算繪製出的ROC Curve的AUC。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "依照題目給定的梯形公式，使用上一題的資料點（TPR, FPR），以0.01為尺度由p=1計算至p=0，求出近似的AUC。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC =  0.903160913113818\n"
     ]
    }
   ],
   "source": [
    "AUC = 0\n",
    "\n",
    "# Right top to left bottom, Make sure FPR and TPR[i-1] > [i]\n",
    "for i in range(1, len(TPR)-1):\n",
    "    height = (TPR[i]+TPR[i-1])/2\n",
    "    width = FPR[i-1]-FPR[i]\n",
    "    area = height*width\n",
    "    AUC += area\n",
    "\n",
    "print(\"AUC = \", AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型的AUC約為0.903，擁有不錯的表現。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第三題 [Logistic Regression with L2 Regularization]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Q1.1 (15%) Derive the gradient and hessian matrix for the new E(w). \n",
    "\n",
    "Origin $E(w) = \\frac{\\lambda}{2} w^T w - \\sum_{i=1}^n [ t_i \\ln y_i  + (1 - t_i) \\ln (1 - y_i)],$  \n",
    "\n",
    "New $E(w) = \\frac{1}{2} w^T \\Lambda w - \\sum_{i=1}^n [ t_i \\ln y_i  + (1 - t_i) \\ln (1 - y_i)],$  \n",
    "where $y_i = \\frac{1}{1 + exp({-w^T x_i})}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Matrix\n",
    "針對新的 $E(w)$ 求 $\\frac{dE(w)}{dw}$  \n",
    "\n",
    "由於新舊兩式不同的地方為 $\\lambda$ to $\\Lambda$，因此代換原本的Gradient Matrix公式：\n",
    "\n",
    "$\\frac{dE(w)}{dw} = \\sum_{i=1}^n (y_i- t_i)x_i + \\lambda w$ to  \n",
    "\n",
    "$\\frac{dE(w)}{dw} = \\sum_{i=1}^n (y_i- t_i)x_i + \\Lambda w$,  \n",
    "where $y_i = \\frac{1}{1 + exp({-w^T x_i})}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hessian Matrix\n",
    "Hessian為 $E(w)$ 的二階導數，因此便是對Gradient在進行一次偏微分：  \n",
    "\n",
    "$\\frac{dGradient}{dw} = \\sum_{i=1}^n y_n(1 - y_n)x_i x_i^T + \\Lambda I$,  \n",
    "where $y_i = \\frac{1}{1 + exp({-w^T x_i})}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Q1.2 (25%) Create your mylogistic_l2 class. Train your model and show the learned $w$ as well as test accuracy for the cases below. If $w$ is too long for you, show selected $w$ for continuous-valued, binary-valued, and the constant term.  \n",
    "  * 依照公式計算Error, Gradient和Hessian，並持續更新w直至進步幅度小於10^-5\n",
    "  * add_intercept決定是否加intercept項"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class mylogistic_l2():\n",
    "    def __init__(self, reg_vec, max_iter = 100, tol = 1e-5, add_intercept = True):\n",
    "        \"\"\"reg_vec: the regularization coefficient vector\n",
    "           max_iter: maximum number of iteration to run for the Newton method\n",
    "           tol: tolerance for the objective function\n",
    "           add_intercept: whether to add intercept (a column of ones) at last column of the feature matrix\"\"\"\n",
    "        ### Add your code here\n",
    "        self.reg_vec = reg_vec\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.add_intercept = add_intercept\n",
    "        \n",
    "    def error(self, w, x, t, lambda_vec):\n",
    "        # error function\n",
    "        error_f = np.dot(np.dot(w.T, np.diag(lambda_vec)), w)\n",
    "        for i in range(x.shape[0]):\n",
    "            y_i = 1/(1+np.exp(-1*np.dot(w.T,x[i,:])))\n",
    "            error_f -= (np.dot(t[i], np.log(y_i)) + np.dot(1-t[i], np.log(1-y_i)))\n",
    "        \n",
    "        return error_f\n",
    "        \n",
    "    def gradient(self, w, x, t, lambda_vec):\n",
    "        # Compute y\n",
    "        y = []\n",
    "        for i in range(x.shape[0]):\n",
    "            y_i = 1/(1+np.exp(-1*np.dot(w.T,x[i,:])))\n",
    "            y.append(y_i)\n",
    "        \n",
    "        # Compute gradient matrix, lambda_mat is a diagonal matrix (1d to 2d)\n",
    "        gradient_mat = np.dot(np.diag(lambda_vec), w) + np.dot(x.T, np.array(y)-t)\n",
    "        return gradient_mat\n",
    "        \n",
    "    def hessian(self, w, x, t, lambda_vec):\n",
    "        # Compute y\n",
    "        y = []\n",
    "        for i in range(x.shape[0]):\n",
    "            y_i = 1/(1+np.exp(-1*np.dot(w.T,x[i,:])))\n",
    "            y.append(y_i)\n",
    "        \n",
    "        # Compute Hessian matrix\n",
    "        R = np.diag(np.array(y)*(1-np.array(y))) # 1D to 2D\n",
    "        hessian_mat = np.dot(np.dot(x.T, R), x) + np.diag(lambda_vec)\n",
    "        return hessian_mat\n",
    "\n",
    "    def fit(self, x, y, verbal = False):\n",
    "        #Add your code here\n",
    "        if self.add_intercept==True:\n",
    "            x = np.c_[x, np.ones(len(x[:,0]))]\n",
    "        \n",
    "        # Initialize w by ridge\n",
    "        b = np.average(self.reg_vec) # Set b to the average of lambda_i\n",
    "        n, m = x.shape\n",
    "        I = np.identity(m) # m*m unit matrix\n",
    "        w_init = np.dot(np.dot(np.linalg.inv(np.dot(x.T, x)+ b * I), x.T), y)\n",
    "        #w_init=np.linalg.inv(np.dot(x.T,x)+np.dot(np.average(self.reg_vec),np.identity(len(self.reg_vec))))\n",
    "        #w_init=np.dot(np.dot(w_init,x.T),y)\n",
    "        w_old = w_init\n",
    "        \n",
    "        for i in range(self.max_iter):\n",
    "            w_new = w_old - np.dot(np.linalg.inv(self.hessian(w_old, x, y, self.reg_vec)), \n",
    "                                   self.gradient(w_old, x, y, self.reg_vec))\n",
    "            \n",
    "            if self.error(w_old, x, y, self.reg_vec)-self.error(w_new, x, y, self.reg_vec) < self.tol:\n",
    "                self.w_new = w_new\n",
    "                return(self.error(w_new, x, y, self.reg_vec))\n",
    "                break\n",
    "                \n",
    "            w_old = w_new\n",
    "                        \n",
    "        self.w_new = w_new\n",
    "        return(self.error(w_new, x, y, self.reg_vec))\n",
    "        \n",
    "    def predict(self, x):\n",
    "        \"\"\"doing prediction\"\"\"\n",
    "        ### add your code here.\n",
    "        if self.add_intercept==True:\n",
    "            x = np.c_[x, np.ones(len(x[:,0]))]\n",
    "        \n",
    "        y_pred = []\n",
    "        for i in range(x.shape[0]):\n",
    "            if 1/(1+np.exp(-1*np.dot(self.w_new.T,x[i,:]))) >= 0.5:\n",
    "                y_pred.append(1)\n",
    "            else:\n",
    "                y_pred.append(0)\n",
    "        return(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Case 1: lambda = 1 for all coefficients\n",
    "  * 此case lambda = 1 * 102 (x_len) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "dsfile = 'adult_m50k.pickle'\n",
    "with open(dsfile, 'rb') as fh1:\n",
    "    adult50kp = pickle.load(fh1)\n",
    "    \n",
    "x_train = adult50kp['x_train']\n",
    "x_test = adult50kp['x_test']\n",
    "y_train = adult50kp['y_train']\n",
    "y_test = adult50kp['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.58310267e-01  3.52949941e-01  2.33388229e+00  7.51143107e-01\n",
      "  3.33523230e-01  7.92367972e-02 -2.59273002e-01 -3.32546362e-02\n",
      " -8.02115295e-01 -1.16297688e+00 -1.57626822e-01  1.06977081e+00\n",
      " -6.33835615e-01  1.16742579e-01 -2.31557179e-01 -5.17113645e-01\n",
      " -7.97119588e-02 -1.09947130e+00 -2.46004516e-01  6.19683549e-02\n",
      "  1.26684041e-01  8.62652911e-01 -9.18352388e-01 -6.21226084e-01\n",
      " -2.00741128e-01 -7.51599172e-01 -1.61005486e+00  5.75818357e-01\n",
      "  6.48992928e-01  3.53740082e-01  7.17215427e-01 -2.84510473e-02\n",
      " -9.54674548e-04 -1.96537318e-01 -1.46346365e-01  6.26952647e-01\n",
      "  4.48206612e-01  2.45949673e-02  4.69218852e-02 -4.91061895e-01\n",
      " -2.03031968e-01 -1.63299787e-01 -1.76576305e-02 -1.11326007e-01\n",
      " -9.94564583e-02 -1.17391707e+00  1.80705584e-01 -6.92683372e-02\n",
      "  9.76497834e-01  4.60990261e-01 -4.95446775e-01 -1.27203068e+00\n",
      "  4.86773385e-01 -8.98962575e-01 -6.00485296e-02 -3.50844313e-01\n",
      "  4.32817972e-01  5.94123037e-01  5.82152577e-01 -6.20957628e-01\n",
      " -5.97456648e-02  9.29048861e-02 -1.51891154e-01 -5.38586869e-03\n",
      "  3.41626371e-02 -2.89083156e-01  1.56053051e-01  4.95403500e-01\n",
      "  8.90941964e-01  1.49151416e-01  3.42481919e-01 -3.13311551e-01\n",
      " -3.55933691e-01 -3.62495387e-01 -6.67247499e-01 -4.08830456e-01\n",
      "  4.47491378e-01  1.37772027e-01  1.41352445e-01 -1.16013791e-01\n",
      " -5.61033701e-02 -9.34582476e-01 -2.92565888e-02 -2.99012002e-01\n",
      " -1.50511724e-01  3.52333045e-01 -7.85850310e-01  5.80201627e-01\n",
      "  4.97049260e-01 -1.90312209e-01 -3.40039918e-04  1.75002411e-01\n",
      " -4.88193872e-01 -3.12251930e-01 -1.02642944e+00 -7.22257752e-01\n",
      "  1.44662468e+00  1.15508166e+00 -6.80148985e-01 -1.21189369e+00\n",
      " -7.98285791e-01 -5.34595942e-01 -1.34547582e+00]\n",
      "Accuracy: 0.847875166002656\n"
     ]
    }
   ],
   "source": [
    "lambda_vec_1 = [1]*(len(x_train[0,:])+1)\n",
    "logic1 = mylogistic_l2(reg_vec = lambda_vec_1, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic1.fit(x_train, y_train)\n",
    "ypred = logic1.predict(x_test)\n",
    "Accuracy = 0\n",
    "for i in range(len(ypred)):\n",
    "    if ypred[i] == y_test[i]:\n",
    "        Accuracy += 1\n",
    "print(logic1.w_new)\n",
    "print(\"Accuracy:\", Accuracy/len(ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "w如上列，Accuracy約為0.8479"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Case 2: lambda = 1 for all but the intercept, no regularization for intercept term.\n",
    "  * 此case lambda = 1 * 102 (x_len) + 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.25833013  0.35307192  2.33346275  0.73787398  0.33384981  0.07926879\n",
      " -0.04216849  0.19971188 -0.5836399  -0.93640484  0.07532238  1.28717898\n",
      " -0.37140237  0.394229    0.04305765 -0.26147417  0.19558989 -0.42695568\n",
      "  0.42695568  0.16423976  0.22840151  0.96471795 -0.81744159 -0.5207484\n",
      " -0.09910763 -0.64944292 -1.55228423  0.6786728   0.75065755  0.45540527\n",
      "  0.81856369  0.07308318  0.07284368 -0.11752577 -0.06282719  0.67243027\n",
      "  0.50408421  0.08798878  0.11434698 -0.38483779 -0.10196335 -0.05145392\n",
      "  0.10741799 -0.01998044  0.01717662 -1.16567613  0.30082132  0.02715475\n",
      "  1.00831182  0.50210408 -0.45757466 -1.24002206  0.52780884 -0.86832678\n",
      " -0.02771015 -0.31412373  0.47343563  0.62981274  0.62405566 -0.58674712\n",
      " -0.02966932  0.12414431 -0.14376162  0.02434021  0.06216112 -0.24843622\n",
      "  0.1945919   0.52620612  0.93165429  0.18707549  0.3794967  -0.28749438\n",
      " -0.31136957 -0.33290724 -0.65117849 -0.38160138  0.48879119  0.17662376\n",
      "  0.1741034  -0.07343499 -0.03146614 -0.89846857  0.00653743 -0.27232552\n",
      " -0.12442223  0.39697125 -0.75319225  0.6106769   0.70543933  0.01790082\n",
      "  0.2090388   0.38274804 -0.27958048 -0.10453074 -0.93101577 -0.52637642\n",
      "  1.61387817  1.36721842 -0.49230267 -1.01487839 -0.60562784 -0.34191128\n",
      " -3.17496423]\n",
      "Accuracy: 0.8477423638778221\n"
     ]
    }
   ],
   "source": [
    "lambda_vec_2 = [1]*(len(x_train[0,:]))\n",
    "lambda_vec_2.append(0) # No regularization for intercept term\n",
    "logic2 = mylogistic_l2(reg_vec = lambda_vec_2, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic2.fit(x_train, y_train)\n",
    "ypred = logic2.predict(x_test)\n",
    "Accuracy = 0\n",
    "for i in range(len(ypred)):\n",
    "    if ypred[i] == y_test[i]:\n",
    "        Accuracy += 1\n",
    "print(logic2.w_new)\n",
    "print(\"Accuracy:\", Accuracy/len(ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "w如上列，Accuracy約為0.8477，略低於case1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Case 3: lambda = 1 for numerical-valued features, lambda = 0.5 for binary-valued features, no regularization for intercept term.\n",
    "  * 由於Q1以對資料進行過排列，前六筆為numerical，後面的為binary\n",
    "  * 此case lambda = 1 * 6 + 0.5 * 96 (x_len - 6) + 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.25851595  0.35333677  2.33560307  0.78258234  0.33439769  0.07940033\n",
      " -0.08343059  0.23288416 -0.59280783 -0.92213633  0.11118913  1.25430145\n",
      " -0.38299411  0.4129183   0.0413606  -0.26411541  0.19283063 -0.42890021\n",
      "  0.42890021  0.23627487  0.30013694  1.03802695 -0.75223416 -0.45348802\n",
      " -0.02698716 -0.58259968 -1.99977423  0.75120146  0.82688921  0.52823094\n",
      "  0.89481188  0.14502733  0.18251138 -0.02585207  0.00990666  0.89860666\n",
      "  0.68514484  0.23291936  0.24517739 -0.38362677 -0.0802979  -0.06493047\n",
      "  0.04537408  0.03742524 -0.01295035 -2.0936429   0.25764153  0.06659333\n",
      "  1.18749024  0.55059181 -0.47577685 -1.458417    0.58222262 -1.06277971\n",
      " -0.00956356 -0.31704111  0.52485313  0.73044944  0.67457113 -0.63623764\n",
      " -0.00966602  0.17339345 -0.23647419  0.03754353  0.10120979 -0.24678934\n",
      "  0.23800205  0.64228564  1.00566602  0.23258649  0.42266914 -0.35336364\n",
      " -0.29178225 -0.38125649 -0.96292148 -0.45008096  0.51298515  0.220197\n",
      "  0.22640438 -0.04989229 -0.01837094 -0.95953566  0.01656882 -0.32741505\n",
      " -0.14011767  0.42855865 -0.84477592  0.75121604  0.76670644  0.07638897\n",
      "  0.26824645  0.44314251 -0.22057982 -0.04631767 -1.28758688 -0.57180269\n",
      "  1.82485625  1.39603933 -0.54684633 -1.05886245 -0.65544642 -0.38793769\n",
      " -3.36246931]\n",
      "Accuracy: 0.847675962815405\n"
     ]
    }
   ],
   "source": [
    "lambda_vec_3 = [1]*(6)\n",
    "lambda_vec_3 = [*lambda_vec_3, *[0.5]*(len(x_train[0,:])-6)]\n",
    "lambda_vec_3.append(0)\n",
    "\n",
    "logic3 = mylogistic_l2(reg_vec = lambda_vec_3, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic3.fit(x_train, y_train)\n",
    "ypred = logic3.predict(x_test)\n",
    "Accuracy = 0\n",
    "for i in range(len(ypred)):\n",
    "    if ypred[i] == y_test[i]:\n",
    "        Accuracy += 1\n",
    "print(logic3.w_new)\n",
    "print(\"Accuracy:\", Accuracy/len(ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "w如上列，Accuracy約為0.8477，略低於case1和case2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Q1.3 (10%) Further split the training data into subtraining (90%) and tuning (10%) to search for the best hyperparameters. Set the regularization coefficient for the constant term to zero. Allow different regularizations for continuous-valued and binary-valued features. Let $a_1$ and $a_2$ denote the regularization coefficients for continuous-valued and binary-valued features. Search the best $a_1$ and $a_2$ and report the test accuracy using the best hyper-parameters. You should follow the following procedure to search for the best hyperparameters. \n",
    "    1. Choose a set of grids among a reasonable range. For example, 10 grids in [0.01, 100]. \n",
    "    2. Conduct grid search with the constraint that $a_1 = a_2$. Record the best value $a_1^*$ and $a_2^*$.\n",
    "    3. Fix $a_1 = a_1^*$, and search $a_2$ for the best value, call the result the new $a_2^*$. \n",
    "    4. Fix $a_2 = a_2^*$, and search $a_1$ for the best value.\n",
    "    5. Report the selected $a_1$ and $a_2$.\n",
    "    6. Train a model using the selected hyper-parameters, and report the test accuracy.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 依照題目的指引進行操作，首先以train-test-split將資料切成9:1，grids則用10^(1/9)次方約等於2.8，進行近似等比的切割。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: 0.01 Accuracy: 0.8518395757374876\n",
      "a: 0.028 Accuracy: 0.8518395757374876\n",
      "a: 0.078 Accuracy: 0.8518395757374876\n",
      "a: 0.22 Accuracy: 0.8518395757374876\n",
      "a: 0.615 Accuracy: 0.8518395757374876\n",
      "a: 1.72 Accuracy: 0.8518395757374876\n",
      "a: 4.82 Accuracy: 0.8525024859131588\n",
      "a: 13.5 Accuracy: 0.8508452104739808\n",
      "a: 37.8 Accuracy: 0.8508452104739808\n",
      "a: 100 Accuracy: 0.8511766655618164\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_subtrain, x_tune, y_subtrain, y_tune = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "# Step 1\n",
    "grids = [0.01, 0.028, 0.078, 0.22, 0.615, 1.72, 4.82, 13.5, 37.8, 100] # 10000^(1/9) ~ 2.8\n",
    "\n",
    "# Step 2\n",
    "Accuracy = 0\n",
    "best_a = 0\n",
    "for a in grids:\n",
    "    lambda_vec=[a]*(len(x_subtrain[0,:]))\n",
    "    lambda_vec.append(0)\n",
    "    logic = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "    logic.fit(x_subtrain, y_subtrain)\n",
    "    \n",
    "    ypred = logic.predict(x_tune)\n",
    "    accu_temp = 0\n",
    "    for i in range(len(ypred)):\n",
    "        if ypred[i] == y_tune[i]:\n",
    "            accu_temp += 1\n",
    "            \n",
    "    if accu_temp > Accuracy:\n",
    "        Accuracy = accu_temp\n",
    "        best_a = a\n",
    "        \n",
    "    print(\"a:\", a, \"Accuracy:\", accu_temp/len(ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2: 0.01 Accuracy: 0.8521710308253232\n",
      "a2: 0.028 Accuracy: 0.8521710308253232\n",
      "a2: 0.078 Accuracy: 0.8521710308253232\n",
      "a2: 0.22 Accuracy: 0.8521710308253232\n",
      "a2: 0.615 Accuracy: 0.8525024859131588\n",
      "a2: 1.72 Accuracy: 0.8521710308253232\n",
      "a2: 4.82 Accuracy: 0.8525024859131588\n",
      "a2: 13.5 Accuracy: 0.8505137553861452\n",
      "a2: 37.8 Accuracy: 0.8508452104739808\n",
      "a2: 100 Accuracy: 0.8495193901226383\n"
     ]
    }
   ],
   "source": [
    "# Step 3\n",
    "Accuracy = 0\n",
    "best_a1 = best_a\n",
    "for a in grids:\n",
    "    lambda_vec = [best_a1]*(6)\n",
    "    lambda_vec = [*lambda_vec, *[a]*(len(x_train[0,:])-6)]\n",
    "    lambda_vec.append(0)\n",
    "    logic = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "    logic.fit(x_subtrain, y_subtrain)\n",
    "    \n",
    "    ypred = logic.predict(x_tune)\n",
    "    accu_temp = 0\n",
    "    for i in range(len(ypred)):\n",
    "        if ypred[i] == y_tune[i]:\n",
    "            accu_temp += 1\n",
    "            \n",
    "    if accu_temp > Accuracy:\n",
    "        Accuracy = accu_temp\n",
    "        best_a = a\n",
    "    \n",
    "    print(\"a2:\", a, \"Accuracy:\", accu_temp/len(ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1: 0.01 Accuracy: 0.8518395757374876\n",
      "a1: 0.028 Accuracy: 0.8518395757374876\n",
      "a1: 0.078 Accuracy: 0.8518395757374876\n",
      "a1: 0.22 Accuracy: 0.8518395757374876\n",
      "a1: 0.615 Accuracy: 0.8518395757374876\n",
      "a1: 1.72 Accuracy: 0.8518395757374876\n",
      "a1: 4.82 Accuracy: 0.8525024859131588\n",
      "a1: 13.5 Accuracy: 0.8525024859131588\n",
      "a1: 37.8 Accuracy: 0.8518395757374876\n",
      "a1: 100 Accuracy: 0.8501823002983095\n"
     ]
    }
   ],
   "source": [
    "# Step 4\n",
    "Accuracy = 0\n",
    "best_a2 = best_a\n",
    "for a in grids:\n",
    "    lambda_vec = [a]*(6)\n",
    "    lambda_vec = [*lambda_vec, *[best_a2]*(len(x_train[0,:])-6)]\n",
    "    lambda_vec.append(0)\n",
    "    logic = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "    logic.fit(x_subtrain, y_subtrain)\n",
    "    \n",
    "    ypred = logic.predict(x_tune)\n",
    "    accu_temp = 0\n",
    "    for i in range(len(ypred)):\n",
    "        if ypred[i] == y_tune[i]:\n",
    "            accu_temp += 1\n",
    "            \n",
    "    if accu_temp > Accuracy:\n",
    "        Accuracy = accu_temp\n",
    "        best_a = a\n",
    "    \n",
    "    print(\"a1:\", a, \"Accuracy:\", accu_temp/len(ypred))\n",
    "\n",
    "best_a1 = best_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best a1 is:  4.82\n",
      "The best a2 is:  0.615\n",
      "Accuracy: 0.847675962815405\n"
     ]
    }
   ],
   "source": [
    "# Step 5\n",
    "print(\"The best a1 is: \", best_a1)\n",
    "print(\"The best a2 is: \", best_a2)\n",
    "# Step 6\n",
    "lambda_vec = [best_a1]*(6)\n",
    "lambda_vec = [*lambda_vec, *[best_a2]*(len(x_train[0,:])-6)]\n",
    "lambda_vec.append(0)\n",
    "logic = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic.fit(x_train, y_train)\n",
    "ypred = logic.predict(x_test)\n",
    "Accuracy = 0\n",
    "for i in range(len(ypred)):\n",
    "    if ypred[i] == y_test[i]:\n",
    "        Accuracy += 1\n",
    "print(\"Accuracy:\", Accuracy/len(ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 最好的a1為4.82，a2則是0.615，這時的tune accuracy約為0.853。\n",
    "* Accuracy約為0.8477，和case3一樣。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Q1.4 (5%) Use sklearn.linear_model.LogisticRegression to train and test the model (including hyperparameter tuning). Compare the estimated parameters and test accuracy with those from your own models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用 sklearn.linear_model的LogisticRegressionCV（和LogisticRegression不同的點在於可以放入複數個C，即Cs），按Q3.1.3的步驟進行，唯\"Cs是lambda_vec的倒數（Inverse）\"。最終探討哪一個的tune accuracy最好，並與Q3.1.3比較。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: 0.01 Accuracy: 0.8518395757374876\n",
      "a: 0.028 Accuracy: 0.8518395757374876\n",
      "a: 0.078 Accuracy: 0.8518395757374876\n",
      "a: 0.22 Accuracy: 0.8518395757374876\n",
      "a: 0.615 Accuracy: 0.8518395757374876\n",
      "a: 1.72 Accuracy: 0.8518395757374876\n",
      "a: 4.82 Accuracy: 0.8521710308253232\n",
      "a: 13.5 Accuracy: 0.8508452104739808\n",
      "a: 37.8 Accuracy: 0.8511766655618164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: 100 Accuracy: 0.8511766655618164\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "# Step 2\n",
    "Accuracy = 0\n",
    "best_a = 0\n",
    "for a in grids:\n",
    "    lambda_vec=[a]*(len(x_subtrain[0,:]))\n",
    "    clf = LogisticRegressionCV(Cs = 1/np.array(lambda_vec), max_iter=1000, tol = 1e-5, fit_intercept = True)\n",
    "    clf.fit(x_subtrain, y_subtrain)\n",
    "    accu_temp = clf.score(x_tune, y_tune)\n",
    "    \n",
    "    if accu_temp > Accuracy:\n",
    "        Accuracy = accu_temp\n",
    "        best_a = a\n",
    "    \n",
    "    print(\"a:\", a, \"Accuracy:\", accu_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2: 0.01 Accuracy: 0.8518395757374876\n",
      "a2: 0.028 Accuracy: 0.8518395757374876\n",
      "a2: 0.078 Accuracy: 0.8518395757374876\n",
      "a2: 0.22 Accuracy: 0.8518395757374876\n",
      "a2: 0.615 Accuracy: 0.8518395757374876\n",
      "a2: 1.72 Accuracy: 0.8518395757374876\n",
      "a2: 4.82 Accuracy: 0.8521710308253232\n",
      "a2: 13.5 Accuracy: 0.8508452104739808\n",
      "a2: 37.8 Accuracy: 0.8518395757374876\n",
      "a2: 100 Accuracy: 0.8518395757374876\n"
     ]
    }
   ],
   "source": [
    "# Step 3\n",
    "Accuracy = 0\n",
    "best_a1 = best_a\n",
    "for a in grids:\n",
    "    lambda_vec = [best_a1]*(6)\n",
    "    lambda_vec = [*lambda_vec, *[a]*(len(x_train[0,:])-6)]\n",
    "    clf = LogisticRegressionCV(Cs = 1/np.array(lambda_vec), max_iter=1000, tol = 1e-5, fit_intercept = True)\n",
    "    clf.fit(x_subtrain, y_subtrain)\n",
    "    accu_temp = clf.score(x_tune, y_tune)\n",
    "            \n",
    "    if accu_temp > Accuracy:\n",
    "        Accuracy = accu_temp\n",
    "        best_a = a\n",
    "    \n",
    "    print(\"a2:\", a, \"Accuracy:\", accu_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1: 0.01 Accuracy: 0.8521710308253232\n",
      "a1: 0.028 Accuracy: 0.8525024859131588\n",
      "a1: 0.078 Accuracy: 0.8521710308253232\n",
      "a1: 0.22 Accuracy: 0.8525024859131588\n",
      "a1: 0.615 Accuracy: 0.8521710308253232\n",
      "a1: 1.72 Accuracy: 0.8521710308253232\n",
      "a1: 4.82 Accuracy: 0.8521710308253232\n",
      "a1: 13.5 Accuracy: 0.8521710308253232\n",
      "a1: 37.8 Accuracy: 0.8525024859131588\n",
      "a1: 100 Accuracy: 0.8525024859131588\n"
     ]
    }
   ],
   "source": [
    "# Step 4\n",
    "Accuracy = 0\n",
    "best_a2 = best_a\n",
    "for a in grids:\n",
    "    lambda_vec = [a]*(6)\n",
    "    lambda_vec = [*lambda_vec, *[best_a2]*(len(x_train[0,:])-6)]\n",
    "    clf = LogisticRegressionCV(Cs = 1/np.array(lambda_vec), max_iter=1000, tol = 1e-5, fit_intercept = True)\n",
    "    clf.fit(x_subtrain, y_subtrain)\n",
    "    accu_temp = clf.score(x_tune, y_tune)\n",
    "            \n",
    "    if accu_temp > Accuracy:\n",
    "        Accuracy = accu_temp\n",
    "        best_a = a\n",
    "    \n",
    "    print(\"a1:\", a, \"Accuracy:\", accu_temp)\n",
    "\n",
    "best_a1 = best_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best a1 is:  0.028\n",
      "The best a2 is:  0.028\n",
      "Accuracy 0.8476095617529881\n"
     ]
    }
   ],
   "source": [
    "# Step 5\n",
    "print(\"The best a1 is: \", best_a)\n",
    "print(\"The best a2 is: \", best_a)\n",
    "# Step 6\n",
    "clf = LogisticRegression(C = a, max_iter=1000, tol = 1e-5, fit_intercept = True)\n",
    "clf.fit(x_train, y_train)\n",
    "print('Accuracy', clf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 最好的組合為a=0.028\n",
    "* 然而其Accuracy約等於0.8476，稍微劣於我們選出的參數。\n",
    "* Tune Accuracy差距有限，同樣的沒有其他依據進行挑選（挑前or挑後？）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
